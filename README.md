# Backup pessoal do bootcamp e detalhes 


São seis aulas. Os tópicos estão divididos dessa maneira:

Encontro 1: Infrastructure as Code para Engenharia de dados (AWS Cloudformation)
Criando buckets no S3 
Criando um banco de dados Redshift 
Criando um stream de dados usando Kinesis 
Gerenciando Permissões
Conectando uma ferramenta de BI ao Redshift

Encontro 2: Integração Contínua e Testes
CI/CD com Github Actions 
Templating com Jinja 
Deploy com AWS CDK
Criando testes para a sua infraestrutura

Encontro 3: Data lakes
Criando um data lake 
AWS Glue para catalogar seus dados 
AWS Athena para fazer queries sob demanda 
Redshift Spectrum

Encontro 4: Transformação de dados com PySpark / EMR:
Criando um cluster EMR (IaC) 
Transformando seus dados em parquet usando PySpark 
Consumindo Kinesis Data Streams usando Structured Streaming

Encontro 5: Orquestrando tarefas com Airflow:
Deploy de Airflow com ECS Fargate (IaC) 
Criando DAGs para extrair dados de uma API e salvar no Data Lake 
Criando DAGs para executar queries SQL no Redshift

Encontro 6: Modelagem de dados com DBT:
Conectando DBT ao Redshift
Criando um modelo de dados
Agendando DBT com Airflow em ECS Fargate 
Gerando documentação 
Rodando testes

Encontra - se material (em português mesmo) no Google sobre cada um desses tópicos, basta pesquisar e assistir alguns 
vídeos no Youtube.

Ferramentas:

Git, GitHub, AWS Redshift, Docker, Python, SQL, Pycharm
